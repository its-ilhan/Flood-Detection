{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13bffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e887ed",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "PRE_DIR = \"PRE-event\"\n",
    "POST_DIR = \"POST-event\"\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8d70d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compute_change_features(pre_arr, post_arr):\n",
    "    pre_arr = pre_arr / 255.0 if pre_arr.max() > 1 else pre_arr\n",
    "    post_arr = post_arr / 255.0 if post_arr.max() > 1 else post_arr\n",
    "    diff = np.abs(post_arr - pre_arr)\n",
    "    return {\n",
    "        'mean_color_change': np.mean(diff),\n",
    "        'max_color_change': np.max(diff),\n",
    "        'std_color_change': np.std(diff),\n",
    "        'green_decrease': np.mean(post_arr[:,:,1] - pre_arr[:,:,1]),\n",
    "        'brightness_change': np.mean(np.mean(post_arr, axis=2) - np.mean(pre_arr, axis=2))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50ce0c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_geojson_features(geojson_path):\n",
    "    if not os.path.exists(geojson_path):\n",
    "        return {}\n",
    "    try:\n",
    "        with open(geojson_path) as f:\n",
    "            data = json.load(f)\n",
    "    except:\n",
    "        return {}\n",
    "    features = {'num_buildings': 0, 'num_roads': 0, 'has_building_damage': False}\n",
    "    for feature in data.get('features', []):\n",
    "        props = feature.get('properties', {})\n",
    "        if props.get('building') is not None:\n",
    "            features['num_buildings'] += 1\n",
    "        if props.get('highway') is not None:\n",
    "            features['num_roads'] += 1\n",
    "        if props.get('flooded') is not None and props.get('flooded') == True:\n",
    "            features['has_building_damage'] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"UNSUPERVISED FLOOD DAMAGE DETECTION PIPELINE\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd377c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP 1: PREPARING DATASET\")\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_files = sorted(glob.glob(\"annotations/*.geojson\"))\n",
    "print(f\"Found {len(annotation_files)} annotation files\")\n",
    "print(f\"Processing all files...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8963868",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, anno_file in enumerate(annotation_files):\n",
    "    tile_name = os.path.basename(anno_file).replace('.geojson', '')\n",
    "    \n",
    "    pre_files = glob.glob(f\"{PRE_DIR}/*{tile_name}.tif\")\n",
    "    post_files = glob.glob(f\"{POST_DIR}/*{tile_name}.tif\")\n",
    "    \n",
    "    if not pre_files:\n",
    "        continue\n",
    "    \n",
    "    for pre_path in pre_files:\n",
    "        if post_files:\n",
    "            post_path = post_files[0]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            pre_img = tf.keras.utils.load_img(pre_path, target_size=IMG_SIZE)\n",
    "            post_img = tf.keras.utils.load_img(post_path, target_size=IMG_SIZE)\n",
    "            \n",
    "            pre_arr = tf.keras.utils.img_to_array(pre_img) / 255.0\n",
    "            post_arr = tf.keras.utils.img_to_array(post_img) / 255.0\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        change_feats = compute_change_features(pre_arr * 255, post_arr * 255)\n",
    "        geojson_feats = extract_geojson_features(anno_file)\n",
    "        \n",
    "        combined_feats = {**change_feats, **geojson_feats}\n",
    "        combined_feats['pre_filename'] = os.path.basename(pre_path)\n",
    "        combined_feats['post_filename'] = os.path.basename(post_path)\n",
    "        combined_feats['tile'] = tile_name\n",
    "        \n",
    "        data_list.append(combined_feats)\n",
    "    \n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(annotation_files)} tiles, {len(data_list)} pairs so far...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_list)\n",
    "print(f\"\\nCreated dataset with {len(df)} image pairs\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b91f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df) > 0:\n",
    "    print(\"\\nSTEP 2: FEATURE STATISTICS\")\n",
    "    print(\"-\" * 70)\n",
    "    print(df[['mean_color_change', 'max_color_change', 'num_buildings', 'num_roads']].describe())\n",
    "    \n",
    "    print(\"\\n\\nSTEP 3: FEATURE ENGINEERING & CLUSTERING\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    feature_cols = [col for col in df.columns if col not in ['pre_filename', 'post_filename', 'tile']]\n",
    "    X = df[feature_cols].fillna(0).values\n",
    "    \n",
    "    print(f\"Feature matrix shape: {X.shape}\")\n",
    "    print(f\"Features used: {feature_cols}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    print(\"\\nFeatures normalized (StandardScaler)\")\n",
    "    \n",
    "    print(\"\\nClustering with KMeans (3 clusters)...\")\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    df['cluster'] = clusters\n",
    "    \n",
    "    print(\"\\n\\nSTEP 4: CLUSTER ANALYSIS\")\n",
    "    print(\"-\" * 70)\n",
    "    for i in range(3):\n",
    "        cluster_data = df[df['cluster'] == i]\n",
    "        print(f\"\\nCluster {i}: {len(cluster_data)} samples ({100*len(cluster_data)/len(df):.1f}%)\")\n",
    "        print(f\"  Color change:  {cluster_data['mean_color_change'].mean():.4f} ± {cluster_data['mean_color_change'].std():.4f}\")\n",
    "        print(f\"  Buildings:     {cluster_data['num_buildings'].mean():.1f} ± {cluster_data['num_buildings'].std():.1f}\")\n",
    "        print(f\"  Roads:         {cluster_data['num_roads'].mean():.1f} ± {cluster_data['num_roads'].std():.1f}\")\n",
    "        print(f\"  Green loss:    {cluster_data['green_decrease'].mean():.4f}\")\n",
    "    \n",
    "    print(\"\\n\\nSTEP 5: SAVING RESULTS\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    df.to_csv('unsupervised_results.csv', index=False)\n",
    "    print(\"✓ Saved detailed results to 'unsupervised_results.csv'\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    for i in range(3):\n",
    "        cluster_data = df[df['cluster'] == i]\n",
    "        plt.scatter(cluster_data['mean_color_change'], cluster_data['num_buildings'], \n",
    "                   label=f'Cluster {i}', alpha=0.6, s=50)\n",
    "    plt.xlabel('Mean Color Change (Damage Indicator)', fontsize=11)\n",
    "    plt.ylabel('Number of Buildings', fontsize=11)\n",
    "    plt.title('Flood Damage Clusters', fontsize=12, fontweight='bold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    cluster_counts = df['cluster'].value_counts().sort_index()\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "    plt.bar(cluster_counts.index, cluster_counts.values, alpha=0.7, color=colors)\n",
    "    plt.title('Cluster Distribution', fontsize=12, fontweight='bold')\n",
    "    plt.xlabel('Cluster ID', fontsize=11)\n",
    "    plt.ylabel('Number of Samples', fontsize=11)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unsupervised_analysis.png', dpi=100, bbox_inches='tight')\n",
    "    print(\"✓ Saved visualization to 'unsupervised_analysis.png'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ANALYSIS COMPLETE!\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    print(\"OUTPUT FILES:\")\n",
    "    print(\"  1. unsupervised_results.csv - Full dataset with cluster assignments\")\n",
    "    print(\"  2. unsupervised_analysis.png - Visualization of clusters\")\n",
    "    print(\"\\nINTERPRETATION GUIDE:\")\n",
    "    print(\"  - Cluster 0: High color change = Likely flood-damaged areas\")\n",
    "    print(\"  - Cluster 1: Medium change = Moderate damage/alteration\")\n",
    "    print(\"  - Cluster 2: Low change = Minimal damage/control areas\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
