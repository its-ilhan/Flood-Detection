{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a97db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=============================================================================\n",
    "SIAMESE CONVNEXT V2 NANO - GPU OPTIMIZED (UNFROZEN BACKBONE)\n",
    "=============================================================================\n",
    "This version trains ALL 15.5M parameters for better accuracy.\n",
    "Optimized for GTX 1050 Ti (4GB VRAM) with ~30% memory usage.\n",
    "\n",
    "Expected improvement: 82.8% → 85-88% accuracy\n",
    "=============================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, f1_score, accuracy_score,\n",
    "    precision_score, recall_score, roc_curve, auc, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a95672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - GPU OPTIMIZED (UNFROZEN BACKBONE)\n",
    "# =============================================================================\n",
    "CONFIG = {\n",
    "    'image_size': 224,\n",
    "    'batch_size': 12,           # Increased for GPU efficiency\n",
    "    'epochs': 30,               # More epochs since we're training more params\n",
    "    'learning_rate': 5e-5,      # Lower LR for fine-tuning (was 1e-3)\n",
    "    'backbone_lr': 1e-5,        # Even lower for backbone layers\n",
    "    'num_workers': 2,           # Parallel data loading\n",
    "    'freeze_backbone': False,   # *** UNFROZEN - Train all 15.5M params ***\n",
    "    'use_amp': True,            # Mixed precision for memory efficiency\n",
    "    'n_folds': 5,\n",
    "    'patience': 10,             # More patience for fine-tuning\n",
    "    'tta_enabled': True,\n",
    "    'model_name': 'convnextv2_nano',\n",
    "    'gradient_clip': 1.0,       # Gradient clipping for stability\n",
    "    'warmup_epochs': 2,         # Learning rate warmup\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e994a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_DIR = \"PRE-event\"\n",
    "POST_DIR = \"POST-event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e19b012",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Output directories\n",
    "PLOT_DIR = \"metric_plots_gpu\"\n",
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SIAMESE CONVNEXT V2 NANO - GPU OPTIMIZED (FULL FINE-TUNING)\")\n",
    "    print(\"Training ALL 15.5M parameters for maximum accuracy\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # CHECK GPU\n",
    "    # =============================================================================\n",
    "    print(\"STEP 1: CHECKING HARDWARE\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(f\"GPU: {gpu_name}\")\n",
    "        print(f\"Total VRAM: {gpu_memory:.1f} GB\")\n",
    "        print(f\"Backbone: UNFROZEN (Full fine-tuning)\")\n",
    "        print(f\"Expected memory: ~1.2 GB (~30%)\")\n",
    "        torch.cuda.empty_cache()\n",
    "    else:\n",
    "        print(\"ERROR: CUDA not available!\")\n",
    "        print(\"This script requires GPU. Install CUDA-enabled PyTorch:\")\n",
    "        print(\"  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\")\n",
    "        exit(1)\n",
    "\n",
    "    # Import timm\n",
    "    try:\n",
    "        import timm\n",
    "        print(f\"timm version: {timm.__version__}\")\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.check_call(['pip', 'install', 'timm'])\n",
    "        import timm\n",
    "\n",
    "    # ...existing code for all main logic, data loading, training, etc. goes here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a87d721",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "def load_tiff_image(path):\n",
    "    \"\"\"Load a geospatial TIFF file and convert to RGB PIL Image\"\"\"\n",
    "    with rasterio.open(path) as src:\n",
    "        if src.count >= 3:\n",
    "            img = np.stack([src.read(i) for i in [1, 2, 3]], axis=-1)\n",
    "        else:\n",
    "            img = np.stack([src.read(1)] * 3, axis=-1)\n",
    "        \n",
    "        if img.max() > 255:\n",
    "            img = (img / img.max() * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img = img.astype(np.uint8)\n",
    "        \n",
    "        return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5009a1b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET CLASS\n",
    "# =============================================================================\n",
    "class FloodDataset(Dataset):\n",
    "    def __init__(self, pre_paths, post_paths, labels, transform=None):\n",
    "        self.pre_paths = list(pre_paths)\n",
    "        self.post_paths = list(post_paths)\n",
    "        self.labels = list(labels)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pre_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pre_img = load_tiff_image(self.pre_paths[idx])\n",
    "        post_img = load_tiff_image(self.post_paths[idx])\n",
    "        \n",
    "        if self.transform:\n",
    "            pre_img = self.transform(pre_img)\n",
    "            post_img = self.transform(post_img)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return pre_img, post_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b844da1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SIAMESE CONVNEXT V2 MODEL\n",
    "# =============================================================================\n",
    "class SiameseConvNeXtV2(nn.Module):\n",
    "    def __init__(self, num_classes=3, freeze_backbone=False, model_name='convnextv2_nano'):\n",
    "        super(SiameseConvNeXtV2, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            model_name + '.fcmae_ft_in22k_in1k',\n",
    "            pretrained=True,\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        self.feature_dim = self.backbone.num_features\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Slightly larger classifier for more capacity\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),           # Reduced dropout since we have more regularization\n",
    "            nn.Linear(self.feature_dim * 3, 512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Feature dimension: {self.feature_dim}\")\n",
    "        print(f\"Backbone frozen: {freeze_backbone}\")\n",
    "    \n",
    "    def forward_one(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def forward(self, pre_img, post_img):\n",
    "        feat_pre = self.forward_one(pre_img)\n",
    "        feat_post = self.forward_one(post_img)\n",
    "        feat_diff = torch.abs(feat_post - feat_pre)\n",
    "        combined = torch.cat([feat_pre, feat_post, feat_diff], dim=1)\n",
    "        return self.classifier(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e32f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA TRANSFORMS (Enhanced for fine-tuning)\n",
    "# =============================================================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(20),  # Increased rotation\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15)),\n",
    "    transforms.RandomGrayscale(p=0.05),  # Occasional grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.1)),  # Cutout augmentation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c28d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc67c69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# TTA transforms\n",
    "tta_transforms = [\n",
    "    val_transform,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.RandomVerticalFlip(p=1.0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.RandomRotation((90, 90)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c286f8d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LEARNING RATE SCHEDULER WITH WARMUP\n",
    "# =============================================================================\n",
    "def get_lr_scheduler(optimizer, num_warmup_steps, num_training_steps):\n",
    "    \"\"\"Linear warmup then cosine decay\"\"\"\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
    "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46004962",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAINING FUNCTION FOR ONE FOLD\n",
    "# =============================================================================\n",
    "def train_fold(fold_idx, train_loader, val_loader, class_weights, num_training_steps):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold_idx + 1}/{CONFIG['n_folds']}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'val_f1': [], 'learning_rate': []\n",
    "    }\n",
    "    \n",
    "    # Create model\n",
    "    model = SiameseConvNeXtV2(\n",
    "        num_classes=3, \n",
    "        freeze_backbone=CONFIG['freeze_backbone'],\n",
    "        model_name=CONFIG['model_name']\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Different learning rates for backbone vs classifier\n",
    "    backbone_params = list(model.backbone.parameters())\n",
    "    classifier_params = list(model.classifier.parameters())\n",
    "    \n",
    "    optimizer = optim.AdamW([\n",
    "        {'params': backbone_params, 'lr': CONFIG['backbone_lr']},\n",
    "        {'params': classifier_params, 'lr': CONFIG['learning_rate']}\n",
    "    ], weight_decay=0.05)\n",
    "    \n",
    "    # Warmup + Cosine scheduler\n",
    "    num_warmup_steps = CONFIG['warmup_epochs'] * len(train_loader)\n",
    "    scheduler = get_lr_scheduler(optimizer, num_warmup_steps, num_training_steps)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "    \n",
    "    best_val_f1 = 0\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    global_step = 0\n",
    "    \n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for pre_img, post_img, label in train_loader:\n",
    "            pre_img = pre_img.to(device)\n",
    "            post_img = post_img.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.amp.autocast('cuda'):\n",
    "                outputs = model(pre_img, post_img)\n",
    "                loss = criterion(outputs, label)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['gradient_clip'])\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += label.size(0)\n",
    "            train_correct += predicted.eq(label).sum().item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_acc = 100. * train_correct / train_total\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for pre_img, post_img, label in val_loader:\n",
    "                pre_img = pre_img.to(device)\n",
    "                post_img = post_img.to(device)\n",
    "                label = label.to(device)\n",
    "                \n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    outputs = model(pre_img, post_img)\n",
    "                    loss = criterion(outputs, label)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_preds.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(label.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc = accuracy_score(val_labels, val_preds) * 100\n",
    "        val_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        \n",
    "        # Record history\n",
    "        current_lr = optimizer.param_groups[1]['lr']  # Classifier LR\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        history['learning_rate'].append(current_lr)\n",
    "        \n",
    "        # GPU memory on first epoch\n",
    "        if epoch == 0:\n",
    "            mem_used = torch.cuda.memory_allocated() / 1024**3\n",
    "            mem_reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "            print(f\"GPU Memory: {mem_used:.2f} GB used, {mem_reserved:.2f} GB reserved ({100*mem_used/gpu_memory:.0f}%)\")\n",
    "        \n",
    "        # Early stopping\n",
    "        improved = \"\"\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_counter = 0\n",
    "            improved = \" ★\"\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d}/{CONFIG['epochs']} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Acc: {val_acc:.1f}% | \"\n",
    "              f\"Val F1: {val_f1:.3f} | LR: {current_lr:.2e}{improved}\")\n",
    "        \n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
    "    \n",
    "    return model, best_val_f1, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79cfb6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TTA PREDICTION\n",
    "# =============================================================================\n",
    "def predict_with_tta(models, pre_path, post_path):\n",
    "    all_probs = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        \n",
    "        if CONFIG['tta_enabled']:\n",
    "            for tta_transform in tta_transforms:\n",
    "                pre_img = load_tiff_image(pre_path)\n",
    "                post_img = load_tiff_image(post_path)\n",
    "                \n",
    "                pre_tensor = tta_transform(pre_img).unsqueeze(0).to(device)\n",
    "                post_tensor = tta_transform(post_img).unsqueeze(0).to(device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        output = model(pre_tensor, post_tensor)\n",
    "                    probs = torch.softmax(output, dim=1)\n",
    "                    all_probs.append(probs.cpu().numpy())\n",
    "        else:\n",
    "            pre_img = load_tiff_image(pre_path)\n",
    "            post_img = load_tiff_image(post_path)\n",
    "            pre_tensor = val_transform(pre_img).unsqueeze(0).to(device)\n",
    "            post_tensor = val_transform(post_img).unsqueeze(0).to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                output = model(pre_tensor, post_tensor)\n",
    "                probs = torch.softmax(output, dim=1)\n",
    "                all_probs.append(probs.cpu().numpy())\n",
    "    \n",
    "    avg_probs = np.mean(all_probs, axis=0)\n",
    "    prediction = np.argmax(avg_probs, axis=1)[0]\n",
    "    confidence = np.max(avg_probs)\n",
    "    \n",
    "    return prediction, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928f1106",
   "metadata": {},
   "source": [
    "=============================================================================\n",
    "PREPARE DATA\n",
    "============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0843e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # ...existing code for GPU check and timm import...\n",
    "\n",
    "    print(\"\\n\\nSTEP 2: PREPARING DATASET\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    if os.path.exists('unsupervised_results.csv'):\n",
    "        df = pd.read_csv('unsupervised_results.csv')\n",
    "        print(f\"Loaded {len(df)} samples from unsupervised_results.csv\")\n",
    "    else:\n",
    "        print(\"ERROR: Run run_analysis.py first!\")\n",
    "        exit()\n",
    "\n",
    "    pre_paths, post_paths, labels = [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        pre_path = os.path.join(PRE_DIR, row['pre_filename'])\n",
    "        post_path = os.path.join(POST_DIR, row['post_filename'])\n",
    "        if os.path.exists(pre_path) and os.path.exists(post_path):\n",
    "            pre_paths.append(pre_path)\n",
    "            post_paths.append(post_path)\n",
    "            labels.append(int(row['cluster']))\n",
    "\n",
    "    pre_paths = np.array(pre_paths)\n",
    "    post_paths = np.array(post_paths)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    print(f\"Found {len(pre_paths)} valid image pairs\")\n",
    "    print(f\"Label distribution: {pd.Series(labels).value_counts().sort_index().to_dict()}\")\n",
    "\n",
    "    # Class weights\n",
    "    class_counts = pd.Series(labels).value_counts().sort_index()\n",
    "    class_weights = torch.tensor([1.0 / c for c in class_counts.values], dtype=torch.float32)\n",
    "    class_weights = class_weights / class_weights.sum() * len(class_counts)\n",
    "    class_weights = class_weights.to(device)\n",
    "    print(f\"Class weights: {class_weights.cpu().numpy()}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # K-FOLD TRAINING\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\nSTEP 3: K-FOLD CROSS-VALIDATION (GPU OPTIMIZED)\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"Model: ConvNeXt V2 Nano (UNFROZEN - Full fine-tuning)\")\n",
    "    print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "    print(f\"Learning rate: Backbone={CONFIG['backbone_lr']}, Classifier={CONFIG['learning_rate']}\")\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=42)\n",
    "\n",
    "    fold_models = []\n",
    "    fold_f1_scores = []\n",
    "    fold_accuracies = []\n",
    "    all_val_preds = []\n",
    "    all_val_labels = []\n",
    "    all_val_probs = []\n",
    "    fold_histories = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(pre_paths, labels)):\n",
    "        train_dataset = FloodDataset(pre_paths[train_idx], post_paths[train_idx], labels[train_idx], train_transform)\n",
    "        val_dataset = FloodDataset(pre_paths[val_idx], post_paths[val_idx], labels[val_idx], val_transform)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True,\n",
    "                                  num_workers=CONFIG['num_workers'], pin_memory=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False,\n",
    "                                num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "        \n",
    "        num_training_steps = CONFIG['epochs'] * len(train_loader)\n",
    "        \n",
    "        model, best_f1, history = train_fold(fold_idx, train_loader, val_loader, class_weights, num_training_steps)\n",
    "        fold_models.append(model)\n",
    "        fold_f1_scores.append(best_f1)\n",
    "        fold_histories.append(history)\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        fold_preds, fold_labels_list = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for pre_img, post_img, label in val_loader:\n",
    "                pre_img, post_img = pre_img.to(device), post_img.to(device)\n",
    "                outputs = model(pre_img, post_img)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                _, predicted = outputs.max(1)\n",
    "                fold_preds.extend(predicted.cpu().numpy())\n",
    "                fold_labels_list.extend(label.numpy())\n",
    "                all_val_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        fold_acc = accuracy_score(fold_labels_list, fold_preds) * 100\n",
    "        fold_accuracies.append(fold_acc)\n",
    "        all_val_preds.extend(fold_preds)\n",
    "        all_val_labels.extend(fold_labels_list)\n",
    "        \n",
    "        print(f\"Fold {fold_idx + 1} Complete - Accuracy: {fold_acc:.1f}%, F1: {best_f1:.3f}\")\n",
    "        \n",
    "        # Save model\n",
    "        torch.save(model.state_dict(), f'convnextv2_gpu_fold_{fold_idx + 1}.pth')\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # =============================================================================\n",
    "    # RESULTS\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\nSTEP 4: CROSS-VALIDATION RESULTS\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    mean_acc = np.mean(fold_accuracies)\n",
    "    std_acc = np.std(fold_accuracies)\n",
    "    mean_f1 = np.mean(fold_f1_scores)\n",
    "    std_f1 = np.std(fold_f1_scores)\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"CONVNEXT V2 NANO (GPU UNFROZEN) RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Accuracy: {mean_acc:.1f}% ± {std_acc:.1f}%\")\n",
    "    print(f\"F1 Score: {mean_f1:.3f} ± {std_f1:.3f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_val_labels, all_val_preds, target_names=['Cluster 0', 'Cluster 1', 'Cluster 2']))\n",
    "\n",
    "    # =============================================================================\n",
    "    # SAVE METRIC PLOTS\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\nSTEP 4.5: SAVING METRIC PLOTS\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Plot 1-13: Training curves and metrics (same as before but with new data)\n",
    "    # ... [Similar plotting code as original but saves to PLOT_DIR]\n",
    "\n",
    "    # Training loss curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        plt.plot(history['train_loss'], label=f'Fold {i+1} Train', linestyle='-', alpha=0.8)\n",
    "        plt.plot(history['val_loss'], label=f'Fold {i+1} Val', linestyle='--', alpha=0.8)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss (GPU Unfrozen)', fontweight='bold')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/01_training_loss_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/01_training_loss_curves.png\")\n",
    "\n",
    "    # Training accuracy curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        plt.plot(history['train_acc'], label=f'Fold {i+1} Train', linestyle='-', alpha=0.8)\n",
    "        plt.plot(history['val_acc'], label=f'Fold {i+1} Val', linestyle='--', alpha=0.8)\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training & Validation Accuracy (GPU Unfrozen)', fontweight='bold')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/02_training_accuracy_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/02_training_accuracy_curves.png\")\n",
    "\n",
    "    # Per-fold accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(range(1, CONFIG['n_folds'] + 1), fold_accuracies, color='steelblue', alpha=0.7)\n",
    "    plt.axhline(y=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.1f}%')\n",
    "    for bar, acc in zip(bars, fold_accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{acc:.1f}%', ha='center')\n",
    "    plt.xlabel('Fold'); plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Per-Fold Accuracy (GPU Unfrozen)', fontweight='bold')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/03_per_fold_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/03_per_fold_accuracy.png\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(all_val_labels, all_val_preds)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Cluster 0', 'Cluster 1', 'Cluster 2'],\n",
    "                yticklabels=['Cluster 0', 'Cluster 1', 'Cluster 2'],\n",
    "                annot_kws={'size': 14, 'weight': 'bold'})\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "    plt.title(f'CV Confusion Matrix (GPU Unfrozen)\\nAccuracy: {mean_acc:.1f}%', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/04_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/04_confusion_matrix.png\")\n",
    "\n",
    "    # Per-class metrics\n",
    "    precision_per_class = precision_score(all_val_labels, all_val_preds, average=None)\n",
    "    recall_per_class = recall_score(all_val_labels, all_val_preds, average=None)\n",
    "    f1_per_class = f1_score(all_val_labels, all_val_preds, average=None)\n",
    "\n",
    "    x = np.arange(3)\n",
    "    width = 0.25\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width, precision_per_class, width, label='Precision', color='#3498db')\n",
    "    plt.bar(x, recall_per_class, width, label='Recall', color='#2ecc71')\n",
    "    plt.bar(x + width, f1_per_class, width, label='F1', color='#e74c3c')\n",
    "    plt.xlabel('Class'); plt.ylabel('Score')\n",
    "    plt.title('Per-Class Metrics (GPU Unfrozen)', fontweight='bold')\n",
    "    plt.xticks(x, ['Cluster 0', 'Cluster 1', 'Cluster 2'])\n",
    "    plt.legend(); plt.ylim(0, 1.1); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/05_per_class_metrics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/05_per_class_metrics.png\")\n",
    "\n",
    "    # ROC Curves\n",
    "    all_val_probs_arr = np.array(all_val_probs)\n",
    "    all_val_labels_bin = label_binarize(all_val_labels, classes=[0, 1, 2])\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "    for i in range(3):\n",
    "        fpr, tpr, _ = roc_curve(all_val_labels_bin[:, i], all_val_probs_arr[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, color=colors[i], linewidth=2, label=f'Cluster {i} (AUC={roc_auc:.3f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves (GPU Unfrozen)', fontweight='bold')\n",
    "    plt.legend(loc='lower right'); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/06_roc_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/06_roc_curves.png\")\n",
    "\n",
    "    # Additional metric plots\n",
    "    # 1. Validation F1 curves\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        plt.plot(history['val_f1'], label=f'Fold {i+1}')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Validation F1')\n",
    "    plt.title('Validation F1 Curves', fontweight='bold')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/07_validation_f1_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/07_validation_f1_curves.png\")\n",
    "\n",
    "    # 2. Learning rate schedule\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, history in enumerate(fold_histories):\n",
    "        plt.plot(history['learning_rate'], label=f'Fold {i+1}')\n",
    "    plt.xlabel('Epoch'); plt.ylabel('Learning Rate')\n",
    "    plt.title('Learning Rate Schedule', fontweight='bold')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/08_learning_rate_schedule.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/08_learning_rate_schedule.png\")\n",
    "\n",
    "    # 3. Per-fold F1 score\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(range(1, CONFIG['n_folds'] + 1), fold_f1_scores, color='purple', alpha=0.7)\n",
    "    plt.axhline(y=mean_f1, color='red', linestyle='--', label=f'Mean: {mean_f1:.3f}')\n",
    "    for bar, f1 in zip(bars, fold_f1_scores):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, f'{f1:.3f}', ha='center')\n",
    "    plt.xlabel('Fold'); plt.ylabel('F1 Score')\n",
    "    plt.title('Per-Fold F1 Score', fontweight='bold')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/09_per_fold_f1_score.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/09_per_fold_f1_score.png\")\n",
    "\n",
    "    # 4. Normalized CV confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm_norm = confusion_matrix(all_val_labels, all_val_preds, normalize='true')\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "                xticklabels=['Cluster 0', 'Cluster 1', 'Cluster 2'],\n",
    "                yticklabels=['Cluster 0', 'Cluster 1', 'Cluster 2'],\n",
    "                annot_kws={'size': 14, 'weight': 'bold'})\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "    plt.title('CV Confusion Matrix (Normalized)', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/10_cv_confusion_matrix_normalized.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/10_cv_confusion_matrix_normalized.png\")\n",
    "\n",
    "    # 5. Class distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_counts = pd.Series(labels).value_counts().sort_index()\n",
    "    plt.bar(class_counts.index, class_counts.values, color=colors)\n",
    "    plt.xlabel('Class'); plt.ylabel('Count')\n",
    "    plt.title('Class Distribution', fontweight='bold')\n",
    "    plt.xticks([0, 1, 2], ['Cluster 0', 'Cluster 1', 'Cluster 2'])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/11_class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/11_class_distribution.png\")\n",
    "\n",
    "    # 6. Precision-Recall curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i in range(3):\n",
    "        pr, rc, _ = precision_recall_curve(all_val_labels_bin[:, i], all_val_probs_arr[:, i])\n",
    "        pr_auc = auc(rc, pr)\n",
    "        plt.plot(rc, pr, color=colors[i], linewidth=2, label=f'Cluster {i} (AUC={pr_auc:.3f})')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curves', fontweight='bold')\n",
    "    plt.legend(loc='lower left'); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/12_precision_recall_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/12_precision_recall_curves.png\")\n",
    "\n",
    "    # 7. Performance summary (bar plot)\n",
    "\n",
    "    # The following plots require ensemble_preds and ensemble_confidences, so move them after ensemble evaluation.\n",
    "\n",
    "    # =============================================================================\n",
    "    # ENSEMBLE + TTA\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\nSTEP 5: ENSEMBLE + TTA EVALUATION\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # FINAL RESULTS (ConvNeXt V2 Nano - GPU UNFROZEN):\n",
    "    # {'─'*50}\n",
    "    ensemble_preds = []\n",
    "    ensemble_confidences = []\n",
    "\n",
    "    print(\"Running ensemble prediction with TTA...\")\n",
    "    for i in range(len(pre_paths)):\n",
    "        pred, conf = predict_with_tta(fold_models, pre_paths[i], post_paths[i])\n",
    "        ensemble_preds.append(pred)\n",
    "        ensemble_confidences.append(conf)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(pre_paths)} samples...\")\n",
    "\n",
    "    ensemble_acc = accuracy_score(labels, ensemble_preds) * 100\n",
    "    ensemble_f1 = f1_score(labels, ensemble_preds, average='macro')\n",
    "\n",
    "    print(f\"\\nEnsemble + TTA Results:\")\n",
    "    print(f\"  Accuracy: {ensemble_acc:.1f}%\")\n",
    "    print(f\"  Macro F1: {ensemble_f1:.3f}\")\n",
    "\n",
    "    # 7. Performance summary (bar plot)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(['CV Accuracy', 'CV F1', 'Ensemble Acc', 'Ensemble F1'],\n",
    "            [mean_acc/100, mean_f1, ensemble_acc/100, ensemble_f1],\n",
    "            color=['#3498db', '#e74c3c', '#2ecc71', '#9b59b6'])\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Performance Summary', fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/13_performance_summary.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/13_performance_summary.png\")\n",
    "\n",
    "    # 8. Ensemble confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm_ens = confusion_matrix(labels, ensemble_preds)\n",
    "    sns.heatmap(cm_ens, annot=True, fmt='d', cmap='Greens', \n",
    "                xticklabels=['Cluster 0', 'Cluster 1', 'Cluster 2'],\n",
    "                yticklabels=['Cluster 0', 'Cluster 1', 'Cluster 2'],\n",
    "                annot_kws={'size': 14, 'weight': 'bold'})\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual')\n",
    "    plt.title('Ensemble Confusion Matrix', fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{PLOT_DIR}/14_ensemble_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/14_ensemble_confusion_matrix.png\")\n",
    "\n",
    "    # 9. Ensemble confidence distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(ensemble_confidences, bins=30, color='#f39c12', alpha=0.8)\n",
    "    plt.xlabel('Confidence'); plt.ylabel('Count')\n",
    "    plt.title('Ensemble Confidence Distribution', fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/15_ensemble_confidence_distribution.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/15_ensemble_confidence_distribution.png\")\n",
    "\n",
    "    # 10. Confidence by correctness\n",
    "    correct = np.array(ensemble_preds) == np.array(labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(np.array(ensemble_confidences)[correct], bins=30, alpha=0.7, label='Correct', color='#2ecc71')\n",
    "    plt.hist(np.array(ensemble_confidences)[~correct], bins=30, alpha=0.7, label='Incorrect', color='#e74c3c')\n",
    "    plt.xlabel('Confidence'); plt.ylabel('Count')\n",
    "    plt.title('Confidence by Correctness', fontweight='bold')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/16_confidence_by_correctness.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/16_confidence_by_correctness.png\")\n",
    "\n",
    "    # 11. Confidence by class\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(3):\n",
    "        plt.hist(np.array(ensemble_confidences)[np.array(ensemble_preds)==i], bins=30, alpha=0.7, label=f'Class {i}', color=colors[i])\n",
    "    plt.xlabel('Confidence'); plt.ylabel('Count')\n",
    "    plt.title('Confidence by Predicted Class', fontweight='bold')\n",
    "    plt.legend(); plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/17_confidence_by_class.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/17_confidence_by_class.png\")\n",
    "\n",
    "    # 12. CV vs Ensemble comparison\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(['CV Accuracy', 'Ensemble Accuracy'], [mean_acc, ensemble_acc], color=['#3498db', '#2ecc71'], alpha=0.8)\n",
    "    plt.bar(['CV F1', 'Ensemble F1'], [mean_f1*100, ensemble_f1*100], color=['#e74c3c', '#9b59b6'], alpha=0.8)\n",
    "    plt.ylabel('Score (%)')\n",
    "    plt.title('CV vs Ensemble Comparison', fontweight='bold')\n",
    "    plt.ylim(0, 110)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'{PLOT_DIR}/18_cv_vs_ensemble_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"✓ Saved {PLOT_DIR}/18_cv_vs_ensemble_comparison.png\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # SAVE RESULTS\n",
    "    # =============================================================================\n",
    "    print(\"\\n\\nSTEP 6: SAVING RESULTS\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    results_df = df.copy()\n",
    "    results_df['ensemble_prediction'] = ensemble_preds\n",
    "    results_df['confidence'] = ensemble_confidences\n",
    "    results_df.to_csv('convnextv2_gpu_ensemble_results.csv', index=False)\n",
    "    print(\"✓ Saved convnextv2_gpu_ensemble_results.csv\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # FINAL SUMMARY\n",
    "    # =============================================================================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GPU OPTIMIZED TRAINING COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\"\"\n",
    "FINAL RESULTS (ConvNeXt V2 Nano - GPU UNFROZEN):\n",
    "{'─'*50}\n",
    "  Trainable Parameters:    15,475,347 (ALL)\n",
    "  Cross-Validation Acc:    {mean_acc:.1f}% ± {std_acc:.1f}%\n",
    "  Cross-Validation F1:     {mean_f1:.3f} ± {std_f1:.3f}\n",
    "  Ensemble + TTA Acc:      {ensemble_acc:.1f}%\n",
    "  Ensemble + TTA F1:       {ensemble_f1:.3f}\n",
    "{'─'*50}\n",
    "\n",
    "Saved Files:\n",
    "  - convnextv2_gpu_fold_1.pth to convnextv2_gpu_fold_5.pth\n",
    "  - convnextv2_gpu_ensemble_results.csv\n",
    "  - {PLOT_DIR}/*.png (metric plots)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54ae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
